{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e356971b-ac37-4e14-b19b-2c60ea608171",
   "metadata": {},
   "source": [
    "Quickest way to setup:\n",
    "\n",
    "- Download and install conda: https://www.anaconda.com/download\n",
    "- `conda install tensorflow`\n",
    "- `pip install tensorflow_datasets \"jax[cpu]\" chex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b7d79-b472-4131-8fcd-3bdab10b80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pylab as plt\n",
    "import chex\n",
    "import tqdm\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454eaaa0-5cab-44db-8763-8e7f52cc37fd",
   "metadata": {},
   "source": [
    "## Download MNIST using tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c3e095-b21c-4dc9-87e0-dc2393ce6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tfds.load('mnist', split='train', shuffle_files=True)\n",
    "test_ds = tfds.load('mnist', split='test', shuffle_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae6d8c-0901-43d9-86d2-38e1e99cd512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfds_to_numpy(ds) -> tuple[jax.Array, jax.Array]:\n",
    "    images, labels = [], []\n",
    "    for example in tfds.as_numpy(ds):\n",
    "        images.append(example['image'] / 255.0)\n",
    "        labels.append(example['label'])\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    binary_images = np.squeeze(images >= 0.5, axis=-1)\n",
    "    return binary_images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce0b837-f25b-451f-b860-6560f71fe28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_binary_images, train_labels = tfds_to_numpy(train_ds)\n",
    "test_binary_images, test_labels = tfds_to_numpy(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c3ce5-da5d-4050-852f-65f1af583e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_binary_images.shape\", train_binary_images.shape)\n",
    "print(\"test_binary_images.shape\", test_binary_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422119fe-4b27-4047-8db3-64f9353d995f",
   "metadata": {},
   "source": [
    "## BernoulliMixture dataclass\n",
    "\n",
    "We define a dataclass to collect all the Bernoulli mixture parameters in a single data structure. The `@chex.dataclass` is needed so that we can pass `BernoulliMixture` instances as valid pytrees into jax jitted functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194664a-c81e-4b3b-a172-1490a9cff34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pixels = np.prod(train_binary_images.shape[1:])\n",
    "\n",
    "@chex.dataclass\n",
    "class BernoulliMixture:\n",
    "    cluster_weights: jax.Array  # (n_clusters,)\n",
    "    cluster_means: jax.Array  # (n_clusters, n_pixels)\n",
    "\n",
    "def init_mixture_params(key: chex.PRNGKey, n_clusters: int, n_pixels: int) -> BernoulliMixture:\n",
    "    \"\"\"Initialize the mixture parameters.\"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e999bf-e84d-47f6-ad71-c395ba4b4549",
   "metadata": {},
   "source": [
    "## Expectation Maximization (EM) implementation\n",
    "\n",
    "Note: for debugging, it may be helpful to remove the `@jax.jit` annotations. But for performance reasons you will want to re-enable the jit annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca95a4-83b4-4dc8-a8e3-f0ebe545655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def log_joint_prob(\n",
    "    params: BernoulliMixture,\n",
    "    binary_images: jax.Array\n",
    ") -> jax.Array:\n",
    "    \"\"\"Compute the log probability log p(x, z) for each example.\n",
    "\n",
    "    Args:\n",
    "        params: the BernoulliMixture to evaluate log probability under.\n",
    "        binary_images: an (n, h, w) shape binary array containing the observations.\n",
    "\n",
    "    Returns:\n",
    "        A (n,) shape array containing log p(x, z) for each input observation.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \n",
    "\n",
    "@jax.jit\n",
    "def log_likelihood(\n",
    "    params: BernoulliMixture,\n",
    "    binary_images: jax.Array\n",
    ") -> jax.Array:\n",
    "    \"\"\"Compute the marginal log probability log p(x) for each example.\n",
    "    \n",
    "    Args:\n",
    "        params: the BernoulliMixture to evaluate log probability under.\n",
    "        binary_images: an (n, h, w) shape binary array containing the observations.\n",
    "\n",
    "    Returns:\n",
    "        A (n,) shape array containing log p(x) for each input observation.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def em_step(\n",
    "    params: BernoulliMixture,\n",
    "    binary_images: jax.Array\n",
    ") -> BernoulliMixture:\n",
    "    \"\"\"Run one Expectation Maximization (EM) step for the Bernoulli mixture model.\n",
    "    \n",
    "    Args:\n",
    "        params: the current BernoulliMixture model.\n",
    "        binary_images: an (n, h, w) shape binary array containing the observations.\n",
    "\n",
    "    Returns:\n",
    "        The updated BernoulliMixture parameters.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b06f39-0f15-48cd-a09a-f06faef5feb3",
   "metadata": {},
   "source": [
    "## Run the EM algorithm\n",
    "\n",
    "Here we run EM for 20 iterations using $k=15$ clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47adf897-e319-4fb9-ad76-8ca88c56b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 15\n",
    "params = init_mixture_params(jax.random.PRNGKey(83832), n_clusters, n_pixels)\n",
    "train_lls, test_lls = [], []\n",
    "for iter in tqdm.tqdm(range(20)):\n",
    "    params = em_step(params, train_binary_images)\n",
    "    train_lls.append(np.mean(log_likelihood(params, train_binary_images)))\n",
    "    test_lls.append(np.mean(log_likelihood(params, test_binary_images)))\n",
    "train_lls, test_lls = np.array(train_lls), np.array(test_lls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fdce26-25d5-4d92-983b-7f19a11441a4",
   "metadata": {},
   "source": [
    "## Evaluate EM results\n",
    "\n",
    "Here we plot various evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1a460f-4718-4934-92f3-dad45f3731fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_lls)\n",
    "plt.plot(test_lls)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Log Likelihood')\n",
    "plt.title('Bernoulli EM, n_clusters={}'.format(n_clusters))\n",
    "plt.legend(('Train', 'Test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc5658-a640-416b-9425-172502db94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "n_rows = 3\n",
    "n_cols = 5\n",
    "\n",
    "fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols)\n",
    "for row_idx in range(n_rows):\n",
    "    for col_idx in range(n_cols):\n",
    "        ax = axs[row_idx][col_idx]\n",
    "        cluster_idx = row_idx * n_cols + col_idx\n",
    "        ax.imshow(params.cluster_means[cluster_idx].reshape((28, 28)))\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.xaxis.set_ticks([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticks([])\n",
    "        ax.set_title(\"$p_{{{}}}={:.3f}$\".format(cluster_idx, params.cluster_weights[cluster_idx]))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e07eb1-dc6c-4644-b58b-673b2c247da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each datapoint, compute a hard assignment \n",
    "train_assignments = np.argmax(log_joint_prob(params, train_binary_images), axis=-1)\n",
    "test_assignments = np.argmax(log_joint_prob(params, test_binary_images), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bf5cad-ccfa-499a-b649-b7bfccf112d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cluster_labels(assignments, labels): \n",
    "    cluster_labels = [{} for _ in range(n_clusters)]\n",
    "    for cluster_assignment, true_label in zip(assignments, labels):\n",
    "        d = cluster_labels[cluster_assignment]\n",
    "        d[true_label] = d.get(true_label, 0) + 1\n",
    "    return cluster_labels\n",
    "\n",
    "train_cluster_labels = make_cluster_labels(train_assignments, train_labels)\n",
    "test_cluster_labels = make_cluster_labels(test_assignments, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3821f26-3d29-4bec-a748-905b550bd7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "n_rows = 3\n",
    "n_cols = 5\n",
    "\n",
    "fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(10, 8))\n",
    "for row_idx in range(n_rows):\n",
    "    for col_idx in range(n_cols):\n",
    "        ax = axs[row_idx][col_idx]\n",
    "        cluster_idx = row_idx * n_cols + col_idx\n",
    "        labels = np.array([l for l, _ in train_cluster_labels[cluster_idx].items()])\n",
    "        counts = np.array([v for _, v in train_cluster_labels[cluster_idx].items()])\n",
    "        ax.bar(labels - 0.2, counts / np.sum(counts), width=0.4)\n",
    "        labels = np.array([l for l, _ in test_cluster_labels[cluster_idx].items()])\n",
    "        counts = np.array([v for _, v in test_cluster_labels[cluster_idx].items()])\n",
    "        ax.bar(labels + 0.2, counts / np.sum(counts), width=0.4)\n",
    "        ax.xaxis.set_ticks(list(range(10)))\n",
    "        if cluster_idx == 0:\n",
    "            ax.legend(('train', 'test'))\n",
    "        ax.set_title(\"$p_{{{}}}={:.3f}$\".format(cluster_idx, params.cluster_weights[cluster_idx]))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6c83c-5ab6-468d-a277-0e111d0e157b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
